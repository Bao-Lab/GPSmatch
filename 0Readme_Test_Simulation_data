#### This readme file explains the the simuation process to create the shuffled BED files with given percentage of binding sites replaced, and use GPSmatch R package to test the accuracy and the mean of jaccard index


######################################## 1. Quality Control of  the BED files in the database ##########
###use "bedtools merge -i file"  to merge redundant regions in a bed file into one region
$ sh ../merge_within_bedfile.sh 
output files to folder to create ./SplitDataBase_mergeregions



############## merge_within_bedfile.sh  ############
#!/bin/bash

cd ~Desktop/Amy_Highschool/BaoNorthwestern/SplitDataBase
mkdir ~/Desktop/Amy_Highschool/BaoNorthwestern/SplitDataBase_mergeregions
for file in ./*
do

    bedtools merge -i $file  > ~/Desktop/Amy_Highschool/BaoNorthwestern/SplitDataBase_mergeregions/$file

done
####################################################


### Make sure all the BED files in the database have the correct format
### We use this script to extract first 3 columns of each bed file, and the output is stored in "Col3DIR_SplitDataBase_mergeregions" directry. 
$ sh Process3Column.sh


################ Process3Column.sh #################
#!/bin/bash

cd ~/Desktop/AmyHighSchool/BaoNorthwestern/SplitDataBase_mergeregions
rm -rf ../Col3DIR_SplitDataBase_mergeregions
mkdir ../Col3DIR_SplitDataBase_mergeregions

ls | while read file; do        
        cat $file | awk '{print $1"\t"$2"\t"$3}' > ../Col3DIR_SplitDataBase_mergeregions/$file
done
####################################################



### We use commandline to format the files in SplitDataBase_mergeregrions directory (cut all lines into 3 columns format) and merge into one big file as a source of background lines to construct shuffled pos and shuffled neg fi$
$ cat ./SplitDataBase_mergeregions/*csv | awk '{print $1"\t"$2"\t"$3}' > SplitDataBase_mergeregions_3col_alllines.csv


###################################### 2. Simulate the shuffled BED files ##############
#### In this readme file, we only used 90% shuffled file as an example. We actually implemented 10%, 20%, 30%, 40%, 50%, 60%, 70%,80%,90% shuffled files using same procedure.

### total lines of binding sites in the database
$ wc -l SplitDataBase_mergeregions_3col_alllines.csv
 339361674 SplitDataBase_mergeregions_3col_alllines.csv

### create the shuffled files with given percentage of replacement, in this example, 90% of the binding sites were randomly replaced by random binding sites from the BED files database. At the same time, 100% replacement were employed to create negative controls. 
$ sh ./ShuffleFiles.sh 0.9 339361674 "~/Desktop/AmyHighSchool/BaoNorthwestern/SplitDataBase_mergeregions_3col_alllines.csv" &


###################################### 3. tested on GPSmatch ################
#Run GPSmatch with each files in the shuffled file directory against the database
in Rstudio, use GPSmatch_AutoRun_Shufflefolder.0.9.R







############## ./ShuffleFiles.sh #######

#!/bin/bash

#####This shell script randomly chose 100 files from the BED file database, and replace a cetain percent of files with randomly selected coordinantes of binding site from the BED file database to create a simulated shuffled BED file


#three command-line input variables
#percentage of lines to replace, 10% means keep 90% lines of the original files
percent=$1
echo "percent=" $percent
#total number of lines in the combined database file
#num_of_lines=$(wc -l "$databaseFile"|awk '{ print $1 }')
num_of_database_lines=$2
echo "number of database file lines = " $num_of_database_lines
#path/name to the combined database file
databaseFile=$3
echo "database file = " $databaseFile

#original data directory
cd ~/Desktop/AmyHighSchool/BaoNorthwestern/Col3DIR_SplitDataBase_mergeregions

#positive data directory
posDIR="Shuffle."$percent".posDIR"
rm -rf ../$posDIR
mkdir ../$posDIR

#negative data directory
negDIR="Shuffle."$percent".negDIR"
rm -rf ../$negDIR
mkdir ../$negDIR

#randomly select 100 BED files from the original data directory and shuffle them into positive and negative cases
ls |sort -R |head -100 |while read file; do     
        echo "file = " $file
        #**create postive control***
        #randomly save '1-percent' lines from the target file
        save=`awk "BEGIN {x=1; y=$percent; z=x-y; print z}"`
        #echo "save = " $save
        perl -ne "print if (rand() < $save)" $file > ../$posDIR/out1.$percent.$file
        
        #count number of lines in the original traget file
        num_of_lines=$(wc -l "$file"|awk '{ print $1 }')  
        #echo "number of lines in the target file = " $num_of_lines     

        #number of line need to select from the combined database file
        replace=`awk "BEGIN {z=$num_of_lines * $percent; print z}"`
        #echo "number of lines for replacement = " $replace
        
        #get ratio of the replacement
        ratioreplace=`awk "BEGIN {z=$replace/$num_of_database_lines; print z}"`
        #echo "positive ratioreplace=" $ratioreplace
        perl -ne "print if (rand() < $ratioreplace)" "$databaseFile" > ../$posDIR/out2.$percent.$file

        #check output line
        #echo "extracted target file line number = " `wc -l ../$posDIR/out1.$percent.$file`
        #echo "extracted database file line number = " `wc -l ../$posDIR/out2.$percent.$file`   

        #merge extracted file
        cat ../$posDIR/out1.$percent.$file ../$posDIR/out2.$percent.$file > ../$posDIR/shuffle_pos.$percent.$file
        rm -f ../$posDIR/out1.$percent.$file ../$posDIR/out2.$percent.$file
########################################################################################
